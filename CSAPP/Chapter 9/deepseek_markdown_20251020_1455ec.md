[파일 이름]: Chapter 9.md
[파일 내용 시작]
https://www.youtube.com/watch?v=Fy9cnP9TXUc&list=PL22J-I2Pi-Gf0s1CGDVtt4vuvlyjLxfem&index=17

## 가상 머신(Virtual Machine)
- **예: 디스크** - 컨트롤러는 커널에 디스크를 일련의 논리 블록 시퀀스로 보여줍니다. 이 뷰를 제공하는 방식은 커널의 I/O 요청을 가로채고, 커널이 보내는 논리 블록 번호를 실제 물리 주소로 변경하는 것입니다.
- ![[Pasted image 20251020131130.png]]
- 자동차, 엘리베이터, 디지털 액자와 같은 임베디드 마이크로컨트롤러 장치와 같은 "단순한" 시스템에서 사용됩니다.

- ![[Pasted image 20251020131409.png]]
- 디스크 컨트롤러가 요청을 가로채서 디스크를 가상화했습니다. 주 메모리 리소스의 경우, 요청은 MMU(Memory Management Unit)라는 하드웨어 구성 요소에 의해 실제로 가로챕니다.
    - CPU가 명령어(예: move 명령어)를 실행하면 유효 주소(E.A.)를 생성합니다. 이것은 가상 주소(V.A.)입니다.
    - CPU는 이 주소를 MMU로 보냅니다. MMU는 '주소 변환(Address Translation)'이라는 과정을 거칩니다.
    - 그 결과 실제 물리 주소(P.A.)를 가리킵니다.

- [05:39](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=05:39.62)
- ![[Pasted image 20251020131937.png]]
- 주소 공간은 데이터 바이트의 집합이 아니라, 이러한 바이트들의 주소들의 "집합"입니다.
- 일반적으로 가상 주소 공간은 물리 주소 공간보다 훨씬 큽니다.
    - 물리 주소 공간은 시스템에 장착된 DRAM의 양에 해당합니다.

## 왜 가상 메모리(VM)를 사용할까?
- 주 메모리를 효율적으로 사용
    - DRAM을 가상 주소 공간의 일부에 대한 캐시로 사용
- 메모리 관리 단순화
    - 각 프로세스가 동일한 균일한 선형 주소 공간을 가짐
- 주소 공간 격리
    - 한 프로세스가 다른 프로세스의 메모리를 간섭할 수 없음
    - 사용자 프로그램은 권한이 있는 커널 정보 및 코드에 접근할 수 없음

- [08:54](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=08:54.25)
## 캐싱 도구로서의 VM
- ![[Pasted image 20251020132918.png]]
- 개념적으로 우리는 가상 메모리를 디스크에 저장된 일련의 바이트 시퀀스로 생각할 수 있습니다. 그리고 디스크에 저장된 해당 가상 메모리의 내용은 DRAM에 캐시됩니다.
- 개념적으로, 가상 메모리는 디스크에 저장된 N개의 연속된 바이트 배열입니다.
- 디스크 상의 배열 내용은 물리 메모리(DRAM 캐시)에 캐시됩니다.
    - 이러한 캐시 블록을 페이지(크기는 P = 2^p 바이트)라고 합니다.

### DRAM 캐시 조직
- DRAM 캐시 조직은 엄청난 미스 패널티에 의해 주도됩니다.
    - DRAM은 SRAM보다 약 10배 느립니다.
    - 디스크는 DRAM보다 약 10,000배 느립니다.
- 결과
    - 큰 페이지(블록) 크기: 일반적으로 4 KB, 때로는 4 MB
    - 완전 연관성(Fully Associative)
        - 충돌 미스(Conflict Miss)가 발생하는 직접 매핑 캐시(Direct Mapped Cache)를 기억해보세요. 캐시의 연관성을 높이면 이러한 충돌 미스의 가능성을 줄일 수 있습니다. 하지만 완전 연관성 캐시(하나의 세트만 있는)가 아니면 완전히 제거할 수는 없습니다.
        - 모든 VP(Virtual Page)는 어떤 PP(Physical Page)에도 위치할 수 있습니다.
            - 완전 연관성입니다. 하나의 세트만 있으며, 각 가상 페이지는 캐시 내 어디든지 갈 수 있습니다.
        - "큰" 매핑 함수가 필요합니다 - 캐시 메모리와 다릅니다.
    - 매우 정교하고 비용이 많이 드는 교체 알고리즘
        - 하드웨어로 구현하기에는 너무 복잡하고 개방적입니다.
            - 캐시 메모리의 경우, 하드웨어는 세트 내에서 병렬 검색을 통해 캐시 라인을 찾았습니다.
            - 하지만 VM과 같은 소프트웨어 캐시의 경우 실현 가능하지 않습니다.
    - Write-through보다 Write-back 사용
        - 가능한 한 오랫동안 디스크에 다시 쓰는 것을 지연하려고 합니다.

- [15:37](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=15:37.44)
## 핵심 자료 구조: 페이지 테이블(Page Table)
- 페이지 테이블은 가상 페이지를 물리 페이지에 매핑하는 페이지 테이블 엔트리(PTE)들의 배열입니다.
    - 프로세스별 커널 자료 구조(DRAM 내)
    - 커널이 각 프로세스 컨텍스트의 일부로 유지하는 메모리 내 자료 구조입니다. 즉, 모든 프로세스는 자신만의 페이지 테이블을 가집니다.
    - PTE K - DRAM 내 물리 페이지 k의 물리 주소를 포함합니다.
    - 페이지 테이블은 페이지들이 저장된 위치를 추적합니다.
        - 이 PTE 1은 VP 1에 해당하며, VP 1은 PP 0에 매핑됩니다.
        - VP2는 PP1에 매핑됩니다.
        - 메모리에 없는 일부 페이지(할당된 페이지)는 디스크에 저장되어 있으며, 이러한 페이지에 대해 페이지 테이블 엔트리는 해당 페이지의 디스크 상 위치를 가리키는 포인터를 포함합니다.
        - null은 할당되지 않음을 의미합니다.
- ![[Pasted image 20251020134944.png]]

### 페이지 히트(Page Hit)
- 페이지 히트: 물리 메모리에 있는 VM 워드에 대한 참조 (DRAM 캐시 히트)
- ![[Pasted image 20251020135415.png]]
- 예: CPU에서 가상 주소를 생성하는 movl 명령어가 있고, MMU가 페이지 테이블에서 조회합니다. 이 가상 주소가 가상 페이지 (PTE2) 내 어딘가에 있다고 가정하면, MMU는 해당 가상 페이지 2의 물리 주소를 추출합니다. 이 경우 페이지는 메모리에 있으며, 메모리에 캐시되어 있으므로 히트입니다. 그리고 이제 메모리는 물리 메모리 주소를 MMU로 반환할 수 있습니다.

### 페이지 폴트(Page Fault)
- 페이지 폴트: 물리 메모리에 없는 VM 워드에 대한 참조 (DRAM 캐시 미스)
- ![[Pasted image 20251020135541.png]]
- 하드웨어가 예외(exception)를 트리거합니다. 이는 커널 내 페이지 폴트 핸들러(Page Fault Handler)라는 코드 청크로 제어를 이전시키며, 핸들러는 이제 쫓아낼 희생자(victim, 이 경우 VP4)를 선택합니다.
- ![[Pasted image 20251020135753.png]]
- 디스크에서 가상 페이지 3을 가져와(fetch) 물리 메모리에 로드(load)합니다. 그리고 VP4가 이제 디스크에 저장되었다는 사실을 반영하기 위해 페이지 테이블 엔트리를 업데이트합니다.
- 만약 가상 페이지 4가 언제든지 수정되었다면, 그 내용을 디스크에 쓰기(write back)도 해야 합니다.
- 핸들러가 가상 페이지 3을 메모리에 복사한 후, 페이지 폴트를 발생시킨 명령어가 이제 재실행될 수 있습니다. 이제 MMU가 해당 페이지에 해당하는 PTE를 확인하면 (메모리에 존재하는 것을) 찾습니다.
- 핵심 개념: 미스가 발생할 때까지 페이지를 DRAM에 복사하는 것을 요구 페이징(Demand Paging)이라고 합니다.
- ![[Pasted image 20251020135935.png]]

- [21:11](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=21:11.15)
- (sbrk 사용과 같은) 공간 할당은 단순히 이 페이지 테이블 엔트리를 변경할 뿐이며, 페이지가 실제로 접근(touched)될 때 캐시로 가져와집니다.
- 가상 메모리의 새로운 페이지(VP 5)를 할당합니다.
- ![[Pasted image 20251020140620.png]]

## 지역성(Locality)이 다시 한번 구출합니다!
- 가상 메모리는 끔찍하게 비효율적으로 보이지만, 지역성 덕분에 작동합니다.
- 어떤 시점에서든 프로그램은 워킹 세트(Working Set)라고 불리는 활성 가상 페이지들의 집합에 접근하는 경향이 있습니다.
    - 시간 지역성(Temporal Locality)이 더 좋은 프로그램은 더 작은 워킹 세트를 가집니다.
- 만약 (워킹 세트 크기 < 주 메모리 크기) 라면
    - 강제 미스(Compulsory Miss) 이후 하나의 프로세스에 대해 좋은 성능
- 만약 (모든 워킹 세트 크기의 합 > 주 메모리 크기) 라면
    - 스래싱(Thrashing): 페이지가 지속적으로 스왑 인/아웃 되는 성능 급감 현상

- [24:04](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=24:04.08)
## 메모리 관리 도구로서의 VM
- 핵심 아이디어: 각 프로세스는 자신만의 가상 주소 공간을 가짐
    - 메모리를 단순한 선형 배열로 볼 수 있음
    - 매핑 함수는 주소들을 물리 메모리 전체에 흩뿌림
        - 잘 선택된 매핑은 지역성을 향상시킬 수 있음
- 각 프로세스는 자신만의 가상 주소 공간을 가지며, 커널은 각 프로세스에 자체적인 별도의 페이지 테이블을 제공하여 이를 구현합니다. 해당 프로세스의 컨텍스트 내에서, 이는 커널이 프로세스를 위해 유지하는 자료 구조일 뿐입니다.
- 이렇게 하면 프로그래머와 도구에게 각 프로세스가 매우 유사한 주소 공간(가상 공간, 같은 크기의 주소 공간, 코드와 데이터가 같은 곳에서 시작함)을 가진다는 뷰를 제공할 수 있지만, 실제로 프로세스가 사용하는 페이지들은 메모리 전체에 흩어져 있을 수 있습니다. 이것은 메모리를 가장 효율적으로 사용하는 방법을 제공합니다.
- ![[Pasted image 20251020142343.png]]

## 메모리 관리 도구로서의 VM (계속)
- 메모리 할당 단순화
    - 각 가상 페이지는 어떤 물리 페이지에도 매핑될 수 있음
    - 가상 페이지는 다른 시간에 다른 물리 페이지에 저장될 수 있음
        - 예: VP1은 PP2가 더 이상 사용되지 않을 때 PP2와 PP6에 매핑될 수 있음
- 프로세스 간 코드 및 데이터 공유
    - 가상 페이지들을 같은 물리 페이지에 매핑 (여기서: PP 6)
        - 특정 코드나 데이터를 공유하기 위해
            - 예: lib.c는 물리 주소에 로드되기만 하면 되며, 다른 VP들은 해당 물리 주소에 매핑되면 됨.

- [29:22](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=29:22.22)
## 링킹(Linking)과 로딩(Loading) 단순화
- **링킹**
    - 각 프로그램은 유사한 가상 주소 공간을 가짐
    - 코드, 데이터, 힙은 항상 같은 주소에서 시작합니다.
- **로딩**
    - execve는 .text 및 데이터 섹션을 위한 가상 페이지를 할당하고 무효(invalid)로 표시된 PTE들을 생성합니다.
    - .text 및 .data 섹션은 가상 메모리 시스템에 의해 요구에 따라 페이지 단위로 복사됩니다.

- [32:57](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=32:57.70)
## 메모리 보호 도구로서의 VM
- PTE에 권한 비트(Permission Bits)를 추가로 확장
- MMU는 각 접근 시 이러한 비트들을 확인합니다.
- ![[Pasted image 20251020143617.png]]

- [37:23](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=37:23.98)
- ![[Pasted image 20251020143830.png]]

## 주소 변환 상세
1. 하나의 가상 주소(VA)가 주어집니다 - n 비트로 구성됩니다; 그리고 p 비트로 크기를 나타낼 수 있는 블록들이 있습니다.
    - 가상 페이지 오프셋(Virtual Page Offset, VPO)은 우리가 캐시에서 보았던 블록 오프셋(Block Offset)과 유사합니다.
    - 가상 페이지 번호(Virtual Page Number, VPN) - VM은 완전 연관성이므로 하나의 세트만 있습니다. 따라서 이를 태그(Tag)처럼 생각하세요.
        - 이 블록을 고유하게 식별하는 것입니다.
    - CPU가 MMU에 가상 주소를 제시하면 - MMU는 VPN을 취하여 그것을 페이지 테이블에 대한 인덱스로 사용합니다.
        - 그리고 물리 페이지 번호(Physical Page Number, PPN)가 페이지 테이블 엔트리에서 나옵니다.
    - 가상 블록 내의 오프셋은 물리 블록 내의 오프셋과 동일할 것입니다.
        - 같은 크기의 블록입니다.
- ![[Pasted image 20251020150615.png]]

### 주소 변환: 페이지 히트(Page Hit)
1. 프로세서가 MMU에 가상 주소를 보냅니다.
2-3) MMU가 메모리 내 페이지 테이블에서 PTE를 가져옵니다.
4) MMU가 캐시/메모리에 물리 주소를 보냅니다.
5) 캐시/메모리가 프로세서에 데이터 워드를 보냅니다.
- ![[Pasted image 20251020150701.png]]

### 주소 변환: 페이지 폴트(Page Fault)
1. 프로세서가 MMU에 가상 주소를 보냅니다.
2-3) MMU가 메모리 내 페이지 테이블에서 PTE를 가져옵니다.
4) 유효 비트(Valid Bit)가 0이므로, MMU는 페이지 폴트 예외를 트리거합니다.
5) 핸들러는 희생자(Victim)를 식별하고 (만약 더티(Dirty)하다면, 디스크에 페이지 아웃(Page Out)합니다.)
6) 핸들러는 새로운 페이지를 페이지 인(Page In)하고 메모리 내 PTE를 업데이트합니다.
7) 핸들러는 원래 프로세스로 돌아가서, 폴트를 발생시킨 명령어를 재시작합니다.

- [45:52](https://www.youtube.com/watch?v=Fy9cnP9TXUc#t=45:52.57)
- ![[Pasted image 20251020151653.png]]

## TLB로 변환 속도 향상
- 페이지 테이블 엔트리(PTE)는 다른 메모리 워드처럼 L1에 캐시됩니다.
    - PTE는 다른 데이터 참조에 의해 쫓겨날(evicted) 수 있습니다.
    - PTE 히트도 여전히 작은 L1 지연을 요구합니다.
- 해결책: TLB(Translation Lookaside Buffer)
    - TLB는 PTE를 캐시하는 하드웨어 캐시입니다.
    - MMU 내의 작은 집합 연관성(Set-Associative) 하드웨어 캐시
    - 가상 페이지 번호(VPN)를 물리 페이지 번호(PPN)에 매핑합니다.
    - 소량의 페이지들에 대한 완전한 페이지 테이블 엔트리들을 포함합니다.
- ![[Pasted image 20251020154028.png]]
- ![[Pasted image 20251020154116.png]]
- ![[Pasted image 20251020154225.png]]

## 다단계 페이지 테이블(Multi-level Page Table)
- ![[Pasted image 20251020154842.png]]
- 이것이 어떻게 공간을 절약할까?
    - 페이지 레벨을 사용하지 않는다면, 사용 여부와 관계없이 모든 가상 페이지에 대한 엔트리를 가진 페이지 테이블이 필요합니다.
    - 이 다단계 방식을 사용하면, 우리가 실제로 사용하는 가상 주소 공간의 부분을 커버하기에 충분한 2단계 페이지 테이블들만 생성하면 됩니다. 그리고 사용하지 않는 가상 주소 공간의 부분(그림의 "갭(Gap)")에 대해서는 페이지 테이블을 가질 필요가 없습니다.

- ![[Pasted image 20251020155128.png]]

## 요약(Summary)
- **프로그래머의 가상 메모리 관점**
    - 각 프로세스는 자신만의 개인 선형 주소 공간을 가짐
    - 다른 프로세스에 의해 손상될 수 없음
- **시스템의 가상 메모리 관점**
    - 가상 메모리 페이지를 캐싱하여 메모리를 효율적으로 사용
        - 지역성 덕분에만 효율적임
    - 메모리 관리와 프로그래밍을 단순화
    - 권한을 확인하기 편리한 개입 지점(Interpositioning Point)을 제공하여 보호를 단순화

[파일 내용 끝]